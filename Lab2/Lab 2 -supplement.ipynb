{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Data Mining Lab 2: Classifiers, University of Victoria, Summer 2023** <br>\n",
    "**TA: Jonas Buro (buro@uvic.ca)**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 2\n",
    "1. Binary Classification\n",
    "2. Performance Measures for Classifiers\n",
    "3. Classification Excercise"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1) Binary Classification\n",
    "\n",
    "The task in binary classification is to design or learn a function $f$, which when applied to feature vector $x$ drawn from the feature space $X$, outputs predicted label $\\hat{y}$ which is equal to $x$'s true label $y$ with high probability.\n",
    "\n",
    "$$ f(x) = \\hat{y}$$\n",
    "\n",
    "Sometimes, it is clear how the the features of $x$ impact its true label $y$. If this relationship is easy to express, then we can explicitly define  $f$ and be sure that it will output the correct classification for any $x \\in X$.\n",
    "\n",
    "Often, it is not clear how the features combine to determine its true label, or, if it is, the relationship is difficult to express. In such instances, supervised machine learning methods can be used to approximate $f$.\n",
    "\n",
    "Some applications of binary classification include:\n",
    "- Detecting spam (is this email spam?)\n",
    "- Disease diagnosis (does this patient have cancer?)\n",
    "- Object recognition (does this image contain a dog?)\n",
    "\n",
    "\n",
    "\n",
    "Some common machine learning methods for binary classification are:\n",
    "- Decision Trees\n",
    "- Random Forests\n",
    "- SVMs\n",
    "- Neural Networks\n",
    "- Logistic Regressors\n",
    "\n",
    "The selection of which model to use depends on the type and quantity of the data; each model has tradeoffs. By experimenting with multiple models and evaluating their performance, the analyst can determine the best choice for the problem at hand, as well as develop intuition for which models fare better under different circumstances."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2) Performance Metrics for Classifiers\n",
    "\n",
    " In predictive modeling using regression, where the goal is to predict a numerical $\\hat{y}$, the analyst is much more interested in knowing by HOW MUCH the predictions are incorrect, not if they ARE incorrect, hence the use of error based evaluation metrics, as opposed to accuracy (ratio of correct predictions).\n",
    "\n",
    "Determining the performance of classifiers is not as straightforward as it is for regressors. For classifiers, accuracy is sometimes not an acceptable metric. Consider a case where the data polarizes heavily towards one class, in this case, the model might achieve high accuracy by learning to just predict the majority class, thus performing poorly on the minority class.\n",
    "\n",
    "A better indicator is to look at the Confusion Matrix:\n",
    "\n",
    "<p align=\"center\">\n",
    "<img src=\"https://static.packt-cdn.com/products/9781838555078/graphics/C13314_06_05.jpg\" alt=\"Confusion Matrix\" width=\"35%\" height=\"35%\">\n",
    "</p>\n",
    "\n",
    "<p align=\"center\">\n",
    "<img src=\"https://onestopdataanalysis.com/wp-content/uploads/2020/02/confusion_matrix.png\" alt=\"Confusion Matrix\" width=\"35%\" height=\"35%\">\n",
    "</p>\n",
    "\n",
    "## Precision and Recall\n",
    "\n",
    "Accuracy evaluates proportion of all correct predictions: $$ a = \\frac{TP + TN}{TP + TN + FP + FN} $$\n",
    "\n",
    "Precision evaluates proportion of positive predictions which are actually correct: $$p = \\frac{TP}{TP + FP}$$\n",
    "\n",
    "Recall evaluates proportion of actual positives which are correctly identified:  $$r = \\frac{TP}{TP + FN}$$\n",
    "\n",
    "These two metrics are in an inverse relationship: Improving precision means reducing FP, which means the model is less likely to make positive predictions. This might result in increasing FNs, reducing recall. \n",
    "\n",
    "Conversely, improving recall means reducing FN, which means the model is more likely to make positive predictions. This might result in more FP, reducing precision. $$ FP \\propto FN $$\n",
    "\n",
    "Context determines which of these is the more valuable metric. Determine which is more important: FP or FN.\n",
    "\n",
    "Consider the problem of cancer prediction in patients. Here, the analyst wants a model with high recall: if someone has cancer, and the model classifies them as being cancer-free (FN), this might be catastrophic as it might be a matter of life or death.\n",
    "\n",
    "In the spam detection problem, the analyst wants a model which has high precision: if a mail is not spam, but is classified as such (FP), it is inconvenient for the user.\n",
    "\n",
    "\n",
    "## F measure\n",
    "Method for striking balance between precision and recall. $$ F_{\\beta} = (1 + \\beta^2) \\frac{Precision * Recall}{(\\beta^2 * Precision) + Recall}  $$\n",
    "\n",
    "Here, $\\beta$ is a tuning parameter, which allows the analyst to specify the importance of one metric relative to the other.\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3) Excercise: Titanic Survivor Prediction\n",
    "\n",
    "The task is to use data from the sinking of the Titanic to predict whether or not a passenger survived or not.\n",
    "\n",
    "The data and information about it is located here: https://www.kaggle.com/competitions/titanic/data\n",
    "\n",
    "Steps:\n",
    "\n",
    "1. Get the data\n",
    "2. Investigate the data\n",
    "3. Prepare the data for ML\n",
    "4. Select a model and train it\n",
    "5. Evaluate your model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading train.csv\n",
      "Downloading test.csv\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import urllib.request\n",
    "\n",
    "# Fetch data\n",
    "TITANIC_PATH = os.path.join(\"datasets\", \"titanic\")\n",
    "DOWNLOAD_URL = \"https://raw.githubusercontent.com/ageron/handson-ml2/master/datasets/titanic/\"\n",
    "\n",
    "def fetch_titanic_data(url=DOWNLOAD_URL, path=TITANIC_PATH):\n",
    "    if not os.path.isdir(path):\n",
    "        os.makedirs(path)\n",
    "    for filename in (\"train.csv\", \"test.csv\"):\n",
    "        filepath = os.path.join(path, filename)\n",
    "        if not os.path.isfile(filepath):\n",
    "            print(\"Downloading\", filename)\n",
    "            urllib.request.urlretrieve(url + filename, filepath)\n",
    "\n",
    "fetch_titanic_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "# Load data\n",
    "\n",
    "def load_titanic_data(filename, titanic_path=TITANIC_PATH):\n",
    "    csv_path = os.path.join(titanic_path, filename)\n",
    "    return pd.read_csv(csv_path)\n",
    "\n",
    "train_data = load_titanic_data(\"train.csv\")\n",
    "test_data = load_titanic_data(\"test.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inspect the data shape and integrity\n",
    "# .head(), .info(), .describe(), .value_counts()\n",
    "\n",
    "# Consider feature engineering at this point, such as replacing null values with medians, removing columns, etc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "# Prepare data for ML algorithms by building a preprocessing pipeline for numeric and categorical values\n",
    "\n",
    "# apply pipeline to train_data\n",
    "# x_train = ...\n",
    "\n",
    "# extract labels from train_data into train_labels\n",
    "# y_train = train_data[\"Survived\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# Select a model and train it using x_train, y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate model \n",
    "# k fold cross validation, confusion matrix"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "Data Mining Lab 1 - May 17th by Keon .ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
